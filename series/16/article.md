# 减少分配：写出对 GC 友好的 Go 代码

大家好，我是汪小成。你有没有经历过这种线上“玄学”：吞吐量没怎么变，但 p99 延迟突然变差；或者某次发布后内存曲线变陡、GC 次数暴涨，服务开始抖动。很多时候罪魁祸首不是锁，不是 IO，而是**分配太多**：对象创建得快、死得也快，GC 被迫频繁工作，最终拖慢系统。本文带你从“为什么分配会变慢”讲到“怎么写更少分配的代码”，并给出一个可运行的小实验，直观看到每种写法的 `allocs/op` 差异。本文结构如下：先准备环境与观测方式，再讲核心概念与设计原因，然后给出完整代码、运行效果、常见坑与进阶练习。

## 目录

1. 环境准备 / 前提知识
2. 核心概念解释（概念 → 示例 → 为什么这么设计）
3. 完整代码示例（可运行）
4. 运行效果 + 截图描述
5. 常见坑 & 解决方案（必写）
6. 进阶扩展 / 思考题

## 1. 环境准备 / 前提知识

### 1.1 环境

- Go 1.22+，根目录使用 `go.work`。
- 本篇目录：`series/16`，示例入口：`series/16/cmd/alloclab/main.go`。

### 1.2 运行命令

```bash
go run ./series/16/cmd/alloclab
```

### 1.3 你需要的“观测意识”

减少分配不是凭感觉改代码，而是遵循三步：

1. **先定位分配热点**：哪个函数/哪段循环在制造对象。
2. **再改写为低分配实现**：预分配、复用、builder、避免转换。
3. **改完再验证**：`allocs/op` 降了没？CPU/延迟有无变化？

本文的示例用 `testing.AllocsPerRun` 做快速对比（适合教学与小实验），真正业务里你还会用到 `pprof allocs`、`go test -bench -benchmem` 等工具（后面章节会系统讲）。

配图建议：
- 一张“延迟尖刺与分配率”的示意图（分配率高 → GC 更忙）。
- 一张“优化步骤：定位→改写→验证”的流程图。

## 2. 核心概念解释

### 2.1 分配（allocation）为什么会让程序变慢

**概念**：分配不仅是 `make/new`，还包括某些隐式分配（字符串拼接、fmt 格式化、[]byte↔string 转换、切片扩容等）。  
**示例**：循环里 `s += "a"` 每次可能产生新字符串；`fmt.Sprintf` 在热路径里会创建临时对象。  
**为什么这么设计**：Go 的抽象是“好用优先”，但你在热点路径需要更贴近底层的写法来控制成本。

### 2.2 GC 友好代码的目标：减少“短命对象风暴”

GC 的痛点往往不是“某个对象太大”，而是“对象太多且太短命”。当你在热路径里频繁制造临时对象：

- GC 次数会增加（上一章讲过阈值与 `GOGC`）。
- CPU 会更多时间花在标记/清理上（`GCCPUFraction` 上升）。
- 延迟会出现更多微小停顿叠加（对 p99 影响明显）。

所以 GC 友好的核心目标很朴素：**能复用就复用、能原地就原地、能预分配就预分配**。

配图建议：一张“短命对象 → GC 频繁 → 延迟抖动”的链路图。

### 2.3 典型低分配技巧（先原则，再落地）

下面这些技巧不是“背八股”，而是可以直接落到代码评审的规则：

1. **预分配容量**：`make([]T, 0, n)`，避免多次扩容与拷贝。
2. **用 builder/buffer 聚合**：字符串用 `strings.Builder`，字节用 `bytes.Buffer`；必要时 `Grow`。
3. **避免 fmt 在热循环里格式化**：优先 `strconv` 系列（`AppendInt`、`Itoa` 等）或直接写入 buffer。
4. **减少表示转换**：减少 `[]byte` ↔ `string` 来回转，尤其是在循环里。
5. **复用大对象**：`sync.Pool` 适合复用临时 buffer；但要控制“放回池里的大小”防止内存膨胀。

为什么这么设计：这些写法把“临时对象”换成“可复用的容器”，把“多次扩容”换成“一次性预留”，让运行时少做重复工作。

### 2.4 怎么衡量“少分配”

你至少要能回答两个问题：

- 每次调用平均分配多少次？（`allocs/op`）
- 每次调用平均分配多少字节？（`B/op`，基准测试里更常见）

本文用 `testing.AllocsPerRun` 输出 `allocs/op`，它非常适合在你写完一个“更 Go 味”的实现后做快速 sanity check。注意它只告诉你“分配次数趋势”，不要把它当成精确性能结论。

配图建议：一张 `allocs/op` 对比条形图（+ 拼接 vs Builder、预分配 vs 不预分配）。

## 3. 完整代码示例（可复制运行）

代码路径：`series/16/cmd/alloclab/main.go`。它对比了 8 种常见写法：

1. `string` 循环 `+` 拼接 vs `strings.Builder` + `Grow`
2. 数字拼接：`fmt.Sprintf` vs `strconv.AppendInt`
3. `slice` 追加：不预分配 vs 预分配 cap
4. `bytes.Buffer`：每次 new vs `sync.Pool` 复用

建议你在跑通后，修改参数（循环次数、数据大小）观察趋势变化：分配次数往往是稳定的，但耗时可能受机器影响更明显。

## 4. 运行效果 + 截图描述

运行命令：

```bash
go run ./series/16/cmd/alloclab
```

示例输出（数值会随环境变化，关注相对关系即可）：

```
string 拼接: +                    | allocs/op=199.00
string 拼接: strings.Builder + Grow | allocs/op=1.00
数字拼接: fmt.Sprintf               | allocs/op=208.00
数字拼接: strconv.AppendInt         | allocs/op=2.00
slice 追加: 不预分配                  | allocs/op=16.00
slice 追加: 预分配 cap               | allocs/op=1.00
bytes.Buffer: 每次 new              | allocs/op=2.00
bytes.Buffer: sync.Pool 复用        | allocs/op=1.00
```

截图建议：

- 终端截图：标出两组最有冲击力的对比（`+` vs Builder、fmt vs strconv）。
- 条形图/脑图：把“技巧 → 降分配原因”画成一张图（适合每 500 字 1 张）。
- 代码截图：截取 `strings.Builder` + `Grow` 与 `make([]T, 0, n)` 两段作为“模板写法”。

## 5. 常见坑 & 解决方案（必写）

1. **只看 `allocs/op` 不看语义**：改成低分配但行为变了（例如复用 buffer 导致数据被覆盖）。解决：先保证正确性，再谈优化；必要时复制输出。
2. **`bytes.Buffer`/`strings.Builder` 复用不 reset**：旧数据混入新结果。解决：每次使用前 `Reset()`，并明确生命周期。
3. **`sync.Pool` 用错场景**：把“长期缓存”放进 Pool，或希望 Pool 一定命中。解决：Pool 只适合临时对象复用，且允许被 GC 清空。
4. **Pool 造成内存膨胀**：把很大的 buffer 放回池，导致长期占用。解决：放回前按阈值丢弃（例如 `if cap(b) > 64<<10 { discard }`）。
5. **预分配过度**：为了减少扩容一次性分配巨大 cap，反而浪费内存。解决：用真实数据估算；能估就估，不能估就接受少量扩容。
6. **在热循环里频繁转换**：例如 `string(b)` 每轮都拷贝。解决：在一个表示上完成处理，最后一次性转换。
7. **过早优化**：为了省几个分配把代码写得难读难测。解决：先用 pprof/基准定位热点，热点才值得“贴近底层”。

配图建议：一张“正确性优先”的警示图；一张 Pool 内存膨胀的示意（大 buffer 进池 → RSS 上升）。

## 6. 进阶扩展 / 思考题

- 把示例里的 `concatPlus` 改成 `strings.Repeat`，观察分配次数与耗时变化，并解释原因。
- 给 `appendNoPrealloc/appendPrealloc` 改成结构体切片（更大元素），观察扩容成本。
- 在 `bufferPool` 里去掉 `Grow`，看看 `allocs/op` 是否变化，理解 Grow 的意义。
- 写一个基准测试（`go test -bench -benchmem`）把 `B/op` 也测出来。
- 思考题：如果你的服务 p99 变差，但 `allocs/op` 下降了，可能是什么原因？（提示：锁、IO、调度、缓存 miss、日志）

---

减少分配的本质不是“写更骚的代码”，而是让热点路径少制造临时对象：预分配、builder/buffer、减少格式化与转换、必要时用 Pool 复用。把本文示例跑一遍，你会获得一个很实用的直觉：哪些写法天然高分配，哪些写法更贴近运行时。下一篇我们会继续深入性能主题（基准与 pprof），把“定位→验证→优化”的闭环真正跑起来。
